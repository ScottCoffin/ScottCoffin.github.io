---
title: "FARM Cluster Intro"
subtitle: "A Primer on the UCD CAES Computing Cluster"
output:
  md_document:
    variant: gfm
preserve_yaml: true
toc: true
---

(delete this)`---
toc: true
excerpt: "Getting you up and running R on the UC Davis FARM computing cluster."
---`(delete this)

```{r opts, echo = FALSE}
title <- "farm-cluster-intro"
knitr::opts_knit$set(base.dir = "/Users/MJ/Github/mcmaurer.github.io/", base.url = "/")
knitr::opts_chunk$set(fig.path = paste0("assets/rmd-images/", title, "/"))
```

## Intro

This post is essentially a writeup of a ~2 hour in-person lesson I did for a few friends who were interested in using the UC Davis CAES FARM computing cluster. They both had a little experience, but not much, working from the command line, and we were all on Macs, so it was pretty easy to sit next to each other and have them follow along. Both of them had similar needs as well: getting some long-running R scripts onto the FARM to free up their computers, and maybe get some performance boosts along the way.

This is by no means a comprehensive lesson on high performance computing, nor is it a comprehensive lesson on using the Unix shell, nor is it a compr... You get the idea: I'm not claiming to know all that much about anything. This lesson is intended to help a novice get their R scripts running on the FARM, using whatever strategy or philosophy I've figured out to get **my** R scripts running on the FARM.

#### What Will Be Covered
- a few commands in Unix shell
- accessing the FARM with SSH
- moving files back and forth between FARM and your computer
- basic SLURM commands on the FARM
- pairing an R script and a SLURM submission script
- general format for saving R results/outputs
- how to install R packages on the FARM

#### What Won't Be Covered
- parallelization of code
    - this is pretty specific to your task
    - I'm not good enough to feel comfortable giving a general overview
- anything on Windows
    - ¯\\_(ツ)_/¯
- a comprehensive description of any single topic
    - I'm not building the base of a pyramid here, I'm building a rickety ladder that will hopefully get you where you need to go
    - you can make that ladder less rickety or use it to access more places by building up a better foundation in the topics I'm touching on
- other clusters
    - I've only ever worked on one cluster
    - while some of this may be generalized to other computing clusters, be careful

## Unix Shell Basics

Terminal, command line, and shell, oh my! I'm going to do a quick rundown of these terms, to start. A Terminal is a program that lets you type text in, and get text back as a response. The command line is just the line where you type in those text commands. Finally, a shell is an application that interprets those text commands, it's almost like a translator between you and the computer, taking the text you type and translating it for the computer, then translating what the computer gives as its response. The default shell for Macs and many Linux distributions is `bash`, which we'll be using today.

Go ahead and open up the Terminal application on your computer. You should be greeted by some type of **prompt**, which will probably involve something with your username, and it'll end with the dollar sign \$. Once you're here, type `ls` and hit `Enter`. Congratulations, you've just run your first shell command! `ls` will list all the files in your current directory, which should be your user by default. Now try typing `pwd` and hitting enter, which will *print working directory*, or where your shell is currently working. On my computer, it is `MJ`, my username. You can also use `~` as a shortcut for your Home directory.

![](/assets/rmd-images/farm-cluster-intro/ls_pwd.gif)

You can add *options* to a command like `ls`, like `ls -a` to list **all** the files in your directory.

![](/assets/rmd-images/farm-cluster-intro/ls_1.gif)

You can check the *manual* page for any function by using the command `man`. For example, `man ls` will bring up the manual page for the `ls` function, which includes all of the possible options you can use. You can scroll up and down the manual page and press `q` to exit the manual page.

Another key function we'll use is `cd`, which we use to change the current working directory. For example, if I'm in my Home directory (my username, MJ), which contains a Documents folder, I can use the command `cd Documents/` to change my working directory to `MJ/Documents`. You can type `pwd` to verify where you've moved to, and `ls` to list all the files in your new working directory. To go up one level from your current working directory, like moving from `MJ/Documents` up to `MJ`, you type `cd ..`. `..` just means "up one level".

We will be using `cd` and `ls` a ton, and we'll introduce other commands as we need them.

## Showing Hidden Files

If you're very observant, you may have noticed some strange files when I ran `ls -a` on my computer, a whole bunch of files that all begin with `.`. These are called "hidden files", and by default, Finder on a Mac will not show them. They typically deal with "under the hood" stuff on your computer, and we're about to get a little bit "under the hood".

If you can see all the hidden files in your Home directory in Finder, then you can skip the next section. If you **don't** see them in Finder, we'll need to change that. If you're on Windows, Google around a little bit to see if this is even a problem for you, I honestly have no idea. Linux should show them by default.

We're going to set up your Mac to permanently show hidden files any time you're looking around in Finder, as this is going to be important in the future. Copy-paste the following code into your Terminal: `defaults write com.apple.finder AppleShowAllFiles YES`. Now hit Enter.

Now go up to the apple icon in your menu bar, select Force Quit, select Finder, and click the Relaunch button. Now all your hidden files should show up in your Finder. We'll be looking at some of these files later on.

## Making a FARM Account

If you go to [the FARM official website](https://wiki.cse.ucdavis.edu/support/systems/farm) and scroll down to the Access Policy section, where you'll find a link to the [Account Request Form](http://wiki.cse.ucdavis.edu/cgi-bin/index2.pl) and instructions on making an account. Please follow these instructions. When you log in to the Account Request Form, it will ask you to upload an *SSH public key*. We'll go through this process next.

## Generating an SSH Key

SSH is a widely-used protocol for securely logging into a computer from another computer. Since the FARM is basically another gigantic computer, this is what we've gotta do.

The way SSH works is that you generate a **key pair**. You can think of this as a pair of extremely weird and long passwords that recognize each other. One is your **public** key and the other is the **private** key. As the names suggest, your public key will get shared with the other computer you want to log into, and the private key stays on your computer and **should never ever ever be shared**. I don't know enough to say "well actually it's ok in this circumstance", and if you're reading this, neither do you, so just never ever share it, ok?

To generate a key pair, we'll use the command `ssh-keygen` with some options. Type out `ssh-keygen -b 4096 -t rsa` to create the type of key recommended by the FARM documentation (I won't get into too much detail here). Hit Enter. You will then be prompted to `Enter file in which to save the key (your_home_directory/.ssh/id_rsa):`. **Just hit enter** to put the keys in the default location. Next, you'll be prompted to enter a passphrase. Choose a hard password, but remember it. This isn't Gmail, if you forget this password, there's no way to get it back. **As you type, nothing will show up**, and this is ok. Just type out your passphrase and hit Enter when you're done. You'll have to retype it again, and then press Enter again. You should now get a confirmation that the key pair was created.

These keys now live in your `.ssh` folder, which resides in your Home directory. You should check to make sure you can get to this location in your Finder. Go look in your Home directory in Finder, and look for the `.ssh` folder. Go into this folder, and you shoud see your private `id_rsa` and public `id_rsa.pub` files.

![](/assets/rmd-images/farm-cluster-intro/ssh_finder.gif)

Now, on the [Account Request Form](http://wiki.cse.ucdavis.edu/cgi-bin/index2.pl), where it says to upload your public `id_rsa.pub` key, you should be able to click the button and navigate to this file and upload it. **Make sure it is the public key you are uploading**. If, at this point, you cannot see your `.ssh` folder (it's still hidden), try restarting your internet browser. Once the file is uploaded, finish off the instructions on making your FARM account. You should get an email when your account is set up and you're able to access the FARM. Be sure to write down your username and any other info you're given.

## Set Up Known Host

Once you've been notified that your FARM account has been created, you should be able to log on to the FARM! Before that, we'll set up some files so that your computer recognizes the FARM as a "Known Host". That way, all we'll have to type to log on to the FARM is `ssh farm`.

To make the necessary file, I'll introduce you to another little command line program that will come in very handy: a text editor called `nano`. `nano` is a very simple text editor that comes standard on most Mac and Linux systems, and you access it from the command line. It's pretty barebones, and I wouldn't do anything too intense with it, but for simple tasks, it's very convenient.

If you type `nano file_name`, it will open nano on that file. If you type `nano new_file_name` it will create a blank file with that name and open nano to edit it. We are going to make a file in our `.ssh` directory called `config`, which will allow us to set up the FARM as a known host. First thing we'll need to do is `cd` into our `.ssh` directory. Assuming you're already in your home directory, you can get there by typing `cd .ssh`. Now use `ls` to check and see what's inside. You should see your `id_rsa` and `id_rsa.pub` files.

Now type out `nano config`. What you see now is the `nano` text editor, editing a blank file called `config`. `nano` might look a bit funky, but it's pretty simple. Type out the text below:

```
Host farm
   HostName agri.cse.ucdavis.edu
   User your-user-name
```

We're telling our `ssh` protocol that there's a host "farm" that you can access with a certain location and username. Now, press `CTRL-X` to exit `nano`. You'll be prompted to write the file before quitting, then asked where to write the file. Press enter to write the file to the name you already gave. You should now be back in your regular Terminal, and if you run `ls`, you'll see there's a new file called "config".


## Logging On and Looking Around

Now that we've told our `ssh` protocol that we have a host called "farm", let's log into it. Open up a new Terminal window and put it next to your current one. I always have one window open to access the FARM and one to access my own computer. In the new Terminal window, type `ssh farm`. This very first time, you may be prompted to accept the FARM as a known host, just go ahead and approve it. You may also be prompted to put in your ssh password, go ahead and enter it. If everything goes correctly, you should be met with a greeting message telling you that you're on the FARM!

In your FARM Terminal window, go ahead and run `pwd` to see where you are. This directory should be your username, and we'll refer to this as your FARM home directory. Use `ls` to see what's here.

## Making Directories and Files

You shouldn't have any folders yet, so let's make a folder called `testing` by using the command `mkdir testing`. We'll be putting all of the files and folders we make for this little tutorial into this folder. This reflects a general principle I will advocate for when working on the FARM: use a consistent and nested directory structure. In other words, put everything into its own folder. For example, I like to have a folder for each project, then folders for data, scripts, and outputs. Each of these contains subfolders as well, and so on. You can definitely overdo it, and it can be annoying to dig 10 levels down to find your files, but I think the worst thing you can do is just throw files onto the FARM willy nilly.

Another good general practice is to make a `README` file to just give a brief explanation of what you're doing with a given folder. Let's use `cd testing` to move into our testing folder, and then use `nano README.md` to create a README file. Once you're in `nano`, just give a brief description of what the `testing` folder is for. Once you're done, use `CTRL-X` to exit.

## `rsync` Basics

Alright, we've now made some files on the FARM, but what if we want to work with files you can't just make from scratch, like data? This will require moving files back and forth between the FARM and your computer, which we'll do with a command called `rsync`. `rsync` is a powerful and flexible way to move files back and forth. The basic syntax is `rsync options source destination`. I just use the same set of options every time I use `rsync`, and I'll describe them briefly: `-a` will move files recursively, meaning it will move a folder, plus everything it contains, and it'll keep timestamps and everything like that; `-v` means verbose, and it just means you'll get a little more info on what files are moving around; `-z` will compress files so they move quicker; `-e` will allow us to specify the proper port to access the FARM through (don't worry too much about this, there's just a dedicated route for moving files to and from the FARM, which we'll use).

All this leads to a general pattern of using `rsync`, which looks like this: `rsync -avze 'ssh -p 2022' source_path destination_path`. The `ssh -p 2022` is just us telling the FARM which port we want to access it through. This will make the FARM happy, and that's all you really need to know about it. One more thing to note: file paths for files on the FARM look a little funky. Here's what the path would look like for the `README` in my `testing` folder: `mjculsha@farm.cse.ucdavis.edu:/home/mjculsha/testing/README.md`. You need to include some information on how to get to the FARM itself.

We will **always** run `rsync` on our own computers and not on the FARM. It's not that you'll mess anything up if you try (don't quote me on this though), it just won't work. This establishes another part of your workflow: you'll almost always have 2 Terminal windows open, one accessing the FARM and one on your own computer. Make sure you've got that setup going on your computer now. On your own computer's Terminal window, create a folder in your home directory called `FARM_learning`. We're going to copy our `README` file over to this folder using `rsync`. To do this, we'll start in our home directory on our computer. Now you'll run `rsync -avze 'ssh -p 2022' farm_username@farm.cse.ucdavis.edu:/home/farm_username/testing/README.md ~/FARM_learning`. This will copy the file from the listed destination to the new location. If you were to leave the `README.md` portion off of the source, `rsync` would copy the entire `testing` folder, and its contents, into the destination folder. This is super useful if you want to transfer a whole bunch of files at once, or move one of your nice and neat self-contained project folders.

You can also move things from your computer to the FARM, using the same `rsync -avze 'ssh -p 2022' source_path destination_path` pattern, and you can move whole folders too. Let's `cd` into our `FARM_learning` directory on our own computer, then make a folder called `dummy_files`. Now `cd` into this folder. We're going to make some blank files by using the `touch` command, which just creates an empty file with a given name. Let's run `touch dummy1 dummy2 dummy3` to create 3 dummy files. Run `ls` to verify that they're in your folder. Now let's use `cd ..` to go back up to our `FARM_learning` directory. Now we're going to move the whole `dummy_files` folder over to the FARM. Let's run `rsync -avze 'ssh -p 2022' dummy_files farm_username@farm.cse.ucdavis.edu:/home/farm_username/testing`. Now let's go over to our FARM Terminal window, and `cd` into our `testing` folder, then run `ls` to make sure our `dummy_files` folder is there. Then `cd` into that folder and check to make sure your dummy files are in there. You can use this same basic pattern to move data or other files onto the FARM with relatively little work.

## `.R` and `.sh` Paired Scripts

Now that we know how to move stuff around, we're ready to start making actual scripts on the FARM. I've found that the best way to keep my scripts nice and neat is to make a pair of scripts for every analysis I run: a script that actually runs the analysis, and a script that controls how the job is submitted to the FARM. One good reason for this is that you can test your actual analysis scripts on your own computer, then when they're working, send them up to the FARM, where they can be submitted with your submission script. For this example, we'll be writing a basic R script and a submission script. They aren't really going to be doing anything special, but they'll have the basic structure of some scripts you might actually want to run. Let's start with the `.R` script. Rather than explain it bit by bit in text, I'll just show you the script including some comments.

In the Terminal window open to the FARM, go into the `testing` directory and type `nano test.R` to start editing a new `R` script. Type a script that matches the following.

```{r, test_r_script, eval=FALSE}
# create object called data that contains the first 5 columns of mtcars
data <- mtcars[1:5]

# print out our data
data

# compute the average mpg of the cars in the dataset
avg_mpg <- mean(data$mpg)

# save the avg_mpg object as a .rds file, in the directory where this script is running
saveRDS(avg_mpg, "avg_mpg_mtcars.rds")

```

There we go! This script does a couple super simple things, using R's built-in mtcars dataset. Two things to notice: 1)  running `data` would normally print out the whole data.frame to the R console, but it will go elsewhere when running the script on the cluster (we'll cover this later), and 2) we'll be saving a `.rds` file, which is what you'll often do when you end up with a model object, like running `model1 <- lm(data, y ~ x)`.

This `.R` script should run on your computer just fine, and that makes it really convenient to write a big ole script on your computer, test it out a bit, then send it up to the cluster. This will be more typical, compared to what we did, which was create a `.R` script directly on the cluster. The next script, however, is going to be specific to the cluster. I'm going to take a minute to talk about SLURM.

### SLURM

Slurm is a piece of software that controls how jobs get allocated across the cluster. The cluster is made up of a bunch of different computing "nodes", which are where all the actual computation gets done. Shocking as it may sound, you're not the only one using the cluster! Tons of different researchers are using the cluster all the time, for jobs with highly varying levels of complexity and computational need. Trying to decide where to put all the jobs may sound like a tall task, but SLURM manages it easily! Essentially, everybody tells SLURM how long they think their job will take, how much computational power it will need, and what "priority" it is (I'll explain priority later). Some researchers, who have bought into the cluster, have access to more powerful computing nodes, but if you're reading this, you'll probably be using the more basic computing nodes.

In order to tell SLURM what our job requires, we're going to make a submission script. This script will be a `.sh` file, which is a `bash` script. As you might recall, `bash` is the language you use in the Terminal, running commands like `ls` and `cd`. Well, we can write scripts that run a bunch of `bash`, just like we can write scripts that run a bunch of `R`. Our submission script is essentially a bunch of instructions to the cluster on how to run our R script. Because the cluster is organized in a more complex way than your computer, and because it's shared by a bunch of other researchers, you've gotta give some pretty specific instructions. I will by no means exhaustively list all the things you can do with a cluster, especially stuff to do with parallelization. All our submission script is gonna do is cover the basics you'll need to submit a job. I'll show you the whole script, and then we'll walk through it line by line.

```{bash, eval = F}
#!/bin/bash

# setting name of job
#SBATCH --job-name=testR

# setting home directory
#SBATCH -D /home/mjculsha/test

# setting standard error output
#SBATCH -e /home/mjculsha/test/slurm_log/sterror_%j.txt

# setting standard output
#SBATCH -o /home/mjculsha/test/slurm_log/stoutput_%j.txt

# setting medium priority
#SBATCH -p med

# setting the max time
#SBATCH -t 0:10:00

# mail alerts at beginning and end of job
#SBATCH --mail-type=BEGIN
#SBATCH --mail-type=END

# send mail here
#SBATCH --mail-user=mjculshawmaurer@ucdavis.edu

# now running the actual script!

# load R
module load R

srun Rscript script.R
```

We're gonna start from the top here. The **very first line** needs to be `#!/bin/bash`. This is a little thing called a shebang, and it essentially tells the computer what program it should use to run the rest of the script. In this case, we're telling the computer we want to use `bash`.

The next thing you might notice is a ton of lines start with `#SBATCH`. All of these lines are directions for SLURM. Each of these lines also has a comment above it, which just starts with `#`. The first couple of lines are setting the name and home directory for the job. The name will help you identify your job later when you look at a list of all the jobs running on the cluster, and it's especially handy if you have multiple jobs running at once. The home directory is going to be the directory that contains everything needed for this particular script, which in our case is the `test` directory.

Next up, we're deciding where to put the output and error logs. These files will be simple text files that contain all of the output or error messages from your scripts, which will be invaluable when something goes wrong. You'll notice that I created a directory under `test` called `slurm_log`, where these will be stored. You can go ahead and create this directory using `mkdir`. Another thing to note is that the `%j` in each of these text file names will get turned into the unique job ID number that gets created when you submit a job. What's nice about this is that you can submit the same script multiple times, maybe tweaking it between runs, and each run will get a unique pair of output and error files. This makes it much easier to fix problems with scripts.

The next two directions are telling SLURM some stuff about how to allocate resources for your job. A job's priority affects how your job may be kicked off a set of resources. Low priority jobs can be killed in favor of higher priority jobs, medium priority jobs can be suspended but will resume afterwards, and high priority jobs will keep the allocated resources until the run finishes. You may now be asking yourself why anybody would ever choose a lower priority job! Well, resources can be allocated more quickly for lower priority jobs, whereas you may have to wait a while for exclusive access for a high priority job. I pretty much run everything on medium priority, which works fine for every R script I've ever run. We also have to tell SLURM the maximum time it will take for your job to run. Asking for more time will also delay the start of your job, so you should only ask for as much as you need. Honestly, for me, this is primarily a wild guess followed by refinement based on previous runs.

Next up, we're setting up what I think is a pretty slick feature: email alerts. You can have an email sent to you when your job starts and finishes, which is really handy when you have jobs that take a few hours to a few days. I pair this with a little Gmail filter that sends all the emails with "slurm" in them to a specific folder. The "job finished" email will get sent whether your job finishes nicely or something goes wrong, so it can be useful to see that your job finished in 2 minutes when you expected it to take 2 days.

Finally, we actually get to run the R script! First, we load up R so the cluster knows we want to use it. Then we use `srun`, which is a SLURM command, followed by `Rscript` and the filepath of our script, **relative to our home directory** that we set earlier.

That's a lot of stuff to submit a job, but the nice thing about this script is that you can pretty much copy it for other jobs, with the necessary modifications to file paths, run times, etc.

## `sinfo` and `squeue`

One last stop before we actually submit our test job!

## Submitting Jobs with `sbatch`

## Checking `stout` and `sterror`

## `rsync` Results Back

## `srun` Interactive R Session

## Set Up Directory for R Packages

## Install R Packages to Directory

## Load Packages from Here
